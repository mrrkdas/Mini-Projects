{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Reccomender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based Filtering\n",
    "        - Uses item features to provide recommendations (uses the features of a certain item to recommend other items with simular features)\n",
    "        - A great example is if a user watches a certain video from a certain set of traits, we can reccomend other videos based on those traits\n",
    "        - A limitation with content-based filtering is that it only leverages item simularities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering\n",
    "        - Uses simularities between items and users simultaneously to provide reccomendations (gives reccomendations to User A based on simular interests of user B)\n",
    "        -Â Explicit Feedback: user giving direct feedback (ratings, comments, etc.)\n",
    "        - Implicit FeedBack: more suttle, your indirect behavior towards an item (watch-time, click-rate, etc.)\n",
    "        - An example could be that user 1 has watched movie A, B, and C but user 2 has only watched movie A and C, we can use info based off of user A and reccomend to user B \n",
    "          that they watch movie B. \n",
    "        - Collaborative Filtering, (too me) is a better route to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative Filtering in practice\n",
    "        - We can assign a values between -1 and 1 to users for interest in certain movies, -1 means the most interest 1 means the least, and we can do the same for movies\n",
    "          -1 means it's more of a certain interest of the user and 1 means it's not in the interest of the user\n",
    "        - In this example we hand-engineered the one-dimensional embeddings, in practice, these embeddings are much higher in dimensions, but we learn these embeddings automatically. \n",
    "          that's the beauty of collborative filtering models. \n",
    "        -  U is the user embeddings and V is the product embeddngs, the product of these 2 is A, which is a predictive feedback matrix.\n",
    "        - Our optimization objectie is to minimize the summation of the squared difference between the feedback labels and the predicted feedback\n",
    "        - We can solve this using SGD or Weighted Alternative Least Squares (WALS), WALS is specific to this problem\n",
    "        - The idea of WALS is that for each iteration we alternate between fix U and solve for V, and then fixing V and solving for U. \n",
    "        - WALS usually converges much faster than SGD, but SGD is more flexible with other loss functions\n",
    "        - We have only talked about observed items, but we still have the un-observed ones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Un-Observed Items in collaborative filtering using matrix factorization\n",
    "        - Matrix Factorization on only the observed items minimizes the objective function which is what we don't want\n",
    "        - We can fix this using weighted-matrix-factorization, we treat unobserved entries as 0, but we also scale the un-observed part of the objective function\n",
    "          so it is not over-weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Recommnder System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movielens-ratings dataset\n",
    "ratings_df = tfds.load(\"movielens/100k-ratings\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0, 'movie_genres': array([7]), 'movie_id': b'357', 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\", 'raw_user_age': 46.0, 'timestamp': 879024327, 'user_gender': True, 'user_id': b'138', 'user_occupation_label': 4, 'user_occupation_text': b'doctor', 'user_rating': 4.0, 'user_zip_code': b'53211'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 21:53:18.289080: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in ratings_df.take(1).as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': array([4]), 'movie_id': b'1681', 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 22:10:09.928006: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Load in movielens-movies data\n",
    "movies_df = tfds.load(\"movielens/100k-movies\", split = \"train\")\n",
    "\n",
    "for x in movies_df.take(1).as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings_df.shuffle(100000, seed = 42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80000)\n",
    "test = shuffled.skip(80000).take(20000)\n",
    "\n",
    "movie_titles = movies_df.batch(1000)\n",
    "user_ids = ratings_df.batch(1000000).map(lambda x: x[\"user_id\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 22:15:52.746030: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot batch tensors with different shapes in component 0. First element had shape [1] and element 1 had shape [2]. [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/rish/Desktop/Mini-Projects/MLProjects/RecommenderSystem.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/MLProjects/RecommenderSystem.ipynb#ch0000013?line=0'>1</a>\u001b[0m unique_movie_titles \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39mconcatenate(\u001b[39mlist\u001b[39;49m(movie_titles)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/MLProjects/RecommenderSystem.ipynb#ch0000013?line=1'>2</a>\u001b[0m unique_user_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39mconcatenate(\u001b[39mlist\u001b[39m(user_ids)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/MLProjects/RecommenderSystem.ipynb#ch0000013?line=3'>4</a>\u001b[0m unique_movie_titles[:\u001b[39m4\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3016\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3018\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3019\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [1] and element 1 had shape [2]. [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_movie_titles[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "        - Tensorflow Youtube Video's (https://www.youtube.com/watch?v=BthUPVwA59s&list=PLQY2H8rRoyvy2MiyUBz5RWZr5MPFkV3qz)\n",
    "        - How to Design and Build a Recommendation System Pipeline in Python (Jill Cates) (https://www.youtube.com/watch?v=v_mONWiFv0k)\n",
    "        - Building a Recommendation System in Python (https://www.youtube.com/watch?v=G4MBc40rQ2k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31b54185ef9236271117b65ccd40447ed8c429f8dbf9fa6a895ee5e4cb482fd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

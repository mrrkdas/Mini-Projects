{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Needed Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_name, _, filenames in os.walk(\"/Users/rish/Desktop/Mini-Projects/ML Projects/Data/archive\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dir_name, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pathlib, random, math\n",
    "import splitfolders\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rish/Desktop/Mini-Projects/MLProjects/fish_data_dir\n",
      "\u001b[34mCatla\u001b[m\u001b[m/   \u001b[34mGrass\u001b[m\u001b[m/   \u001b[34mGulfaam\u001b[m\u001b[m/ \u001b[34mSilver\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%mkdir fish_data_dir\n",
    "%cd fish_data_dir\n",
    "%mkdir Catla Silver Gulfaam Grass\n",
    "\n",
    "%cp /Users/rish/Desktop/Mini-Projects/MLProjects/Data/archive/train/Catla*.JPG Catla/\n",
    "%cp /Users/rish/Desktop/Mini-Projects/MLProjects/Data/archive/train/Silver*.JPG Silver/\n",
    "%cp /Users/rish/Desktop/Mini-Projects/MLProjects/Data/archive/train/Gulfaam*.JPG Gulfaam/\n",
    "%cp /Users/rish/Desktop/Mini-Projects/MLProjects/Data/archive/train/Grass*.JPG Grass/\n",
    "\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "img_hieght, img_width = 300, 300\n",
    "input_shape = (img_hieght, img_width, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_sparse(data_bs):\n",
    "    data_bs = pathlib.Path(data_bs)\n",
    "    splitfolders.ratio(data_bs, output=\"Img/\", seed = 42, ratio = (0.7, 0.15, 0.15), group_prefix=None)\n",
    "    data_gen = ImageDataGenerator(rescale=1.0/255)\n",
    "    train_ds = data_gen.flow_from_directory(\"Img/train/\", target_size = (img_hieght, img_width), class_mode = 'sparse', \n",
    "                                            batch_size = batch_size, subset = \"training\")\n",
    "    val_ds = data_gen.flow_from_directory(\"Img/val/\", target_size = (img_hieght, img_width), class_mode = 'sparse', \n",
    "                                            batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    return train_ds, val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 119 files [00:01, 110.14 files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81 images belonging to 5 classes.\n",
      "Found 16 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = create_data_sparse(\"/Users/rish/Desktop/Mini-Projects/MLProjects/fish_data_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 15:29:12.355725: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = \"relu\", input_shape = input_shape),\n",
    "    tf.keras.layers.Conv2D(16, (2,2), activation = \"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(30, activation = \"relu\"),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", \n",
    "metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 298, 298, 32)      896       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 297, 297, 16)      2064      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 148, 148, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 350464)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               35046500  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                3030      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,052,521\n",
      "Trainable params: 35,052,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31b54185ef9236271117b65ccd40447ed8c429f8dbf9fa6a895ee5e4cb482fd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

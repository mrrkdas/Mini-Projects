{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrrkdas/Mini-Projects/blob/main/GAN_with_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQGIX4NHOREK"
      },
      "source": [
        "# All the code here is based off of the [tensorflow article](https://www.tensorflow.org/tutorials/generative/dcgan) on GANs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SUjjSFNfOo9v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2umish_gSvb"
      },
      "source": [
        "## Getting the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZBBbloGg97d",
        "outputId": "b4257746-beb0-4ce3-80ed-56a893b8c61f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFpoWrBsg_7P",
        "outputId": "e9c31be6-1f21-49dc-dfd4-1f7cbf4e1e21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YolNrah3h3EE"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "train_images = (train_images - 127.5) / 127.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TZd-oLrzii4g"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r_bLDIb4jN0K"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-27 15:20:44.666897: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeA5shfLkaqC"
      },
      "source": [
        "## Creating the models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hqlu4sXjkyk4"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(7*7*256, use_bias = False, input_shape = (100,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((7, 7, 256)))\n",
        "  assert model.output_shape == (None, 7, 7, 256) # Checking if the reshape worked\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (5,5), strides = (1,1), padding = 'same', use_bias = False))\n",
        "  assert model.output_shape == (None, 7, 7, 128) # Checking if Conv2DTranspose Layer worked\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5,5), strides = (2,2), padding = 'same', use_bias = False))\n",
        "  assert model.output_shape == (None, 14, 14, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(1, (5,5), strides =(2,2), padding = 'same', use_bias = False, activation = 'tanh' ))\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "RTAu06D57zEd",
        "outputId": "f9e7e34f-8986-479d-cffa-97e94f48d075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbcc79003a0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create an image\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1,100])\n",
        "generated_image = generator(noise, training = False)\n",
        "\n",
        "plt.imshow(generated_image[0, :,:, 0], cmap = 'gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q5GSImYw9hXe"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (5,5), strides = (2,2), padding = 'same', input_shape = [28,28,1]))\n",
        "\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (5,5), strides = (2,2), padding = 'same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ8YQdzC-54R",
        "outputId": "69639cff-a4c6-4fd7-ca11-d5a08a61a70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.00157217]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Using Generated image in discriminator model\n",
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01OSb5Ym_BQi"
      },
      "source": [
        "## Loss Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a2_cp_N7_vzq"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o33ErXT6_2D4"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "  total_loss = real_loss + fake_loss\n",
        "\n",
        "  return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FIUgOw-4Ahs9"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYNw2jyuA_Sw"
      },
      "source": [
        "## Optimizer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yNyrhct5BA6Y"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcBlW8ZcuxKy"
      },
      "source": [
        "## Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g_5GCXnXuyvS"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhgcSTeoBE7S"
      },
      "source": [
        "## Define Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p-ZiRtAFt-js"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BHtXQfWcu_ZT"
      },
      "outputs": [],
      "source": [
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WsBeROKwvHTT"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "\n",
        "def train_step(images):\n",
        "  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training = True)\n",
        "\n",
        "    real_output = discriminator(images, training = True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "    \n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "c6OTh56JyCoe"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GdL4jsXzyUy4"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jbFKVADSyW2l"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/rish/Desktop/Mini-Projects/ML Projects/GAN_with_MNIST.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/ML%20Projects/GAN_with_MNIST.ipynb#ch0000028?line=0'>1</a>\u001b[0m train(train_dataset, EPOCHS)\n",
            "\u001b[1;32m/Users/rish/Desktop/Mini-Projects/ML Projects/GAN_with_MNIST.ipynb Cell 27'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/ML%20Projects/GAN_with_MNIST.ipynb#ch0000026?line=2'>3</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/ML%20Projects/GAN_with_MNIST.ipynb#ch0000026?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m image_batch \u001b[39min\u001b[39;00m dataset:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/ML%20Projects/GAN_with_MNIST.ipynb#ch0000026?line=5'>6</a>\u001b[0m   train_step(image_batch)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/ML%20Projects/GAN_with_MNIST.ipynb#ch0000026?line=8'>9</a>\u001b[0m display\u001b[39m.\u001b[39mclear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/ML%20Projects/GAN_with_MNIST.ipynb#ch0000026?line=9'>10</a>\u001b[0m generate_and_save_images(generator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/ML%20Projects/GAN_with_MNIST.ipynb#ch0000026?line=10'>11</a>\u001b[0m                          epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rish/Desktop/Mini-Projects/ML%20Projects/GAN_with_MNIST.ipynb#ch0000026?line=11'>12</a>\u001b[0m                          seed)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(train_dataset, EPOCHS)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNH8Elo7BcJ9NxtxyO3/uEU",
      "include_colab_link": true,
      "name": "**Mini Project** GAN with MNIST ",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "31b54185ef9236271117b65ccd40447ed8c429f8dbf9fa6a895ee5e4cb482fd5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
